{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U git+https://github.com/albumentations-team/albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 한번만 받으면 됨\n",
    "# !wget http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    pretrained='torchvision://resnet50',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch'),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=11,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=32,\n",
      "    workers_per_gpu=0,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='../../input/data/train.json',\n",
      "        img_prefix='../../input/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        classes=('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal',\n",
      "                 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery',\n",
      "                 'Clothing')),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='../../input/data/val.json',\n",
      "        img_prefix='../../input/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(512, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal',\n",
      "                 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery',\n",
      "                 'Clothing')),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='../../input/data/test.json',\n",
      "        img_prefix='../../input/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(512, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal',\n",
      "                 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery',\n",
      "                 'Clothing')))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[20, 30, 40])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=13)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(\n",
      "    interval=40,\n",
      "    hooks=[dict(type='TensorboardLoggerHook'),\n",
      "           dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "seed = 2020\n",
      "gpu_ids = [0]\n",
      "work_dir = './work_dirs/faster_rcnn_r50_fpn_1x_trash_std'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = (\"UNKNOWN\", \"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile('./configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py')\n",
    "\n",
    "PREFIX = '../../input/data/'\n",
    "\n",
    "\n",
    "# dataset 바꾸기\n",
    "cfg.data.train.classes = classes\n",
    "cfg.data.train.img_prefix = PREFIX\n",
    "cfg.data.train.ann_file = PREFIX + 'train.json'\n",
    "cfg.data.train.pipeline[2]['img_scale'] = (512, 512)\n",
    "\n",
    "cfg.data.val.classes = classes\n",
    "cfg.data.val.img_prefix = PREFIX\n",
    "cfg.data.val.ann_file = PREFIX + 'val.json'\n",
    "cfg.data.val.pipeline[1]['img_scale'] = (512, 512)\n",
    "\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = PREFIX\n",
    "cfg.data.test.ann_file = PREFIX + 'test.json'\n",
    "cfg.data.test.pipeline[1]['img_scale'] = (512, 512)\n",
    "\n",
    "cfg.data.samples_per_gpu = 32\n",
    "cfg.data.workers_per_gpu = 0\n",
    "\n",
    "cfg.seed=2020\n",
    "cfg.gpu_ids = [0]\n",
    "\n",
    "cfg.work_dir = './work_dirs/faster_rcnn_r50_fpn_1x_trash_std'\n",
    "cfg.load_from = 'faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "\n",
    "cfg.model.roi_head.bbox_head.num_classes = 11\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.runner.max_epochs = 13\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=500,\n",
    "    warmup_ratio=0.001,\n",
    "    step=[20, 30, 40])\n",
    "cfg.log_config = dict(  # config to register logger hook\n",
    "    interval=40,  # Interval to print the log\n",
    "    hooks=[\n",
    "        dict(type='TensorboardLoggerHook'),  # The Tensorboard logger is also supported\n",
    "        dict(type='TextLoggerHook')\n",
    "])\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 06:15:27,811 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2021-05-13 06:15:27,812 - mmdet - INFO - Use load_from_torchvision loader\n",
      "2021-05-13 06:15:28,054 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.83s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 06:15:35,975 - mmdet - INFO - load checkpoint from faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "2021-05-13 06:15:35,976 - mmdet - INFO - Use load_from_local loader\n",
      "2021-05-13 06:15:36,133 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([12, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([44, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([44]).\n",
      "2021-05-13 06:15:36,138 - mmdet - INFO - Start running, host: root@6745ed26df0a, work_dir: /opt/ml/code/mmdetection_trash/work_dirs/faster_rcnn_r50_fpn_1x_trash_std\n",
      "2021-05-13 06:15:36,139 - mmdet - INFO - workflow: [('train', 1)], max: 13 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.88s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 06:17:15,108 - mmdet - INFO - Epoch [1][40/82]\tlr: 1.578e-03, eta: 0:42:14, time: 2.470, data_time: 0.395, memory: 13295, loss_rpn_cls: 0.1316, loss_rpn_bbox: 0.0534, loss_cls: 1.1077, acc: 73.6685, loss_bbox: 0.4820, loss: 1.7747, grad_norm: 5.4359\n",
      "2021-05-13 06:18:50,274 - mmdet - INFO - Epoch [1][80/82]\tlr: 3.177e-03, eta: 0:39:50, time: 2.379, data_time: 0.340, memory: 13295, loss_rpn_cls: 0.0777, loss_rpn_bbox: 0.0478, loss_cls: 0.4770, acc: 87.2243, loss_bbox: 0.4756, loss: 1.0781, grad_norm: 1.2095\n",
      "2021-05-13 06:18:55,146 - mmdet - INFO - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 655/655, 18.0 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 06:19:33,377 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.60s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=7.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.26s).\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n",
      "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.089\n",
      "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.042\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.013\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.047\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.077\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.104\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.104\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.037\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.103\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 06:21:21,233 - mmdet - INFO - Epoch [2][40/82]\tlr: 4.855e-03, eta: 0:37:41, time: 2.458, data_time: 0.404, memory: 13295, loss_rpn_cls: 0.0738, loss_rpn_bbox: 0.0493, loss_cls: 0.4000, acc: 89.1681, loss_bbox: 0.3731, loss: 0.8963, grad_norm: 1.3509\n",
      "2021-05-13 06:22:56,247 - mmdet - INFO - Epoch [2][80/82]\tlr: 6.454e-03, eta: 0:36:01, time: 2.375, data_time: 0.334, memory: 13295, loss_rpn_cls: 0.0656, loss_rpn_bbox: 0.0460, loss_cls: 0.3676, acc: 89.7015, loss_bbox: 0.3186, loss: 0.7978, grad_norm: 1.3896\n",
      "2021-05-13 06:23:01,015 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 655/655, 17.9 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 06:23:38,853 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=6.36s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.02s).\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.184\n",
      "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.104\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.023\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.116\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.197\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.244\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.244\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.070\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.244\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.441\n"
     ]
    }
   ],
   "source": [
    "train_detector(model, datasets[0], cfg, distributed=False, validate=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
