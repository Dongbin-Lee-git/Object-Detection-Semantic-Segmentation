{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블을 해보자!\n",
    "- k fold 용으로 각 fold 불러오는 것 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config file 들고오기\n",
    "cfg = Config.fromfile('./configs/custom_augmentation/faster_rcnn_mosaic.py')\n",
    "\n",
    "# Multi scale\n",
    "cfg.data.test.pipeline[1]['img_scale'] = [(1000, 600),(1333, 800),(1666, 1000)]\n",
    "\n",
    "# checkpoint path\n",
    "epoch = 24\n",
    "checkpoint_path = os.path.join(cfg.work_dir, f'epoch_{epoch}.pth')\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "# checkpoint path\n",
    "checkpoint_path0 = './work_dirs/faster_rcnn_kfold0/epoch_12.pth'\n",
    "checkpoint_path1 = './work_dirs/faster_rcnn_kfold1/epoch_12.pth'\n",
    "checkpoint_path2 = './work_dirs/faster_rcnn_kfold2/epoch_12.pth'\n",
    "checkpoint_path3 = './work_dirs/faster_rcnn_kfold3/epoch_12.pth'\n",
    "checkpoint_path4 = './work_dirs/faster_rcnn_kfold4/epoch_12.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋은 한번만 해도 될듯\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-12 00:54:46,226 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2021-05-12 00:54:46,227 - mmdet - INFO - Use load_from_torchvision loader\n",
      "2021-05-12 00:54:46,452 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "model0 = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint0 = load_checkpoint(model0, checkpoint_path0, map_location='cpu')\n",
    "\n",
    "model0.CLASSES = dataset.CLASSES\n",
    "model0 = MMDataParallel(model0.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-12 00:54:47,202 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2021-05-12 00:54:47,203 - mmdet - INFO - Use load_from_torchvision loader\n",
      "2021-05-12 00:54:47,391 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "model1 = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint1 = load_checkpoint(model1, checkpoint_path1, map_location='cpu')\n",
    "\n",
    "model1.CLASSES = dataset.CLASSES\n",
    "model1 = MMDataParallel(model1.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-12 00:54:48,114 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2021-05-12 00:54:48,115 - mmdet - INFO - Use load_from_torchvision loader\n",
      "2021-05-12 00:54:48,289 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "model2 = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint2 = load_checkpoint(model2, checkpoint_path2, map_location='cpu')\n",
    "\n",
    "model2.CLASSES = dataset.CLASSES\n",
    "model2 = MMDataParallel(model2.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-12 00:54:48,982 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2021-05-12 00:54:48,983 - mmdet - INFO - Use load_from_torchvision loader\n",
      "2021-05-12 00:54:49,212 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "model3 = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint3 = load_checkpoint(model3, checkpoint_path3, map_location='cpu')\n",
    "\n",
    "model3.CLASSES = dataset.CLASSES\n",
    "model3 = MMDataParallel(model3.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-12 00:54:49,914 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2021-05-12 00:54:49,915 - mmdet - INFO - Use load_from_torchvision loader\n",
      "2021-05-12 00:54:50,093 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "model4 = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint4 = load_checkpoint(model4, checkpoint_path4, map_location='cpu')\n",
    "\n",
    "model4.CLASSES = dataset.CLASSES\n",
    "model4 = MMDataParallel(model4.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 837/837, 34.0 task/s, elapsed: 25s, ETA:     0s[                                                  ] 0/837, elapsed: 0s, ETA:[                                                  ] 0/837, elapsed: 0s, ETA:[                                                  ] 0/837, elapsed: 0s, ETA:[                                                  ] 0/837, elapsed: 0s, ETA:"
     ]
    }
   ],
   "source": [
    "output0 = single_gpu_test(model0, data_loader, show_score_thr=0.05)\n",
    "output1 = single_gpu_test(model0, data_loader, show_score_thr=0.05)\n",
    "output2 = single_gpu_test(model2, data_loader, show_score_thr=0.05)\n",
    "output3 = single_gpu_test(model0, data_loader, show_score_thr=0.05)\n",
    "output4 = single_gpu_test(model0, data_loader, show_score_thr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ensemble-boxes in /opt/conda/lib/python3.7/site-packages (1.0.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from ensemble-boxes) (1.18.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from ensemble-boxes) (1.2.4)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from ensemble-boxes) (0.53.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->ensemble-boxes) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->ensemble-boxes) (2.8.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba->ensemble-boxes) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->ensemble-boxes) (46.4.0.post20200518)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->ensemble-boxes) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ensemble-boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 다른 모델 앙상블\n",
    "- 저장된 pkl 파일 불러오기\n",
    "- kfold 앙상블시 위에서 inference한 output0~4까지 이용"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output0 = mmcv.load('./ensemble_pkl/universenet.pkl')\n",
    "output1 = mmcv.load('./ensemble_pkl/vfnet_5601.pkl')\n",
    "output2 = mmcv.load('./ensemble_pkl/gflv2.pkl')\n",
    "output3 = mmcv.load('./ensemble_pkl/swin.pkl')\n",
    "# output4 = mmcv.load('./ensemble_pkl/')\n",
    "# output5 = mmcv.load('./ensemble_pkl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_boxes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 0.056775387 159.57796 67.95561 255.01704 167...</td>\n",
       "      <td>batch_01_vt/0021.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 0.098784536 286.33960 337.71945 306.88809 37...</td>\n",
       "      <td>batch_01_vt/0028.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 0.11180874 235.40033 460.90344 302.91647 511...</td>\n",
       "      <td>batch_01_vt/0031.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 0.088503465 293.09857 156.78738 365.58768 22...</td>\n",
       "      <td>batch_01_vt/0032.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 0.091454516 37.98398 459.40359 88.38715 473....</td>\n",
       "      <td>batch_01_vt/0070.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PredictionString              image_id\n",
       "0  0 0.056775387 159.57796 67.95561 255.01704 167...  batch_01_vt/0021.jpg\n",
       "1  0 0.098784536 286.33960 337.71945 306.88809 37...  batch_01_vt/0028.jpg\n",
       "2  0 0.11180874 235.40033 460.90344 302.91647 511...  batch_01_vt/0031.jpg\n",
       "3  0 0.088503465 293.09857 156.78738 365.58768 22...  batch_01_vt/0032.jpg\n",
       "4  0 0.091454516 37.98398 459.40359 88.38715 473....  batch_01_vt/0070.jpg"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_strings = []\n",
    "file_names = []\n",
    "coco = COCO(cfg.data.test.ann_file)\n",
    "imag_ids = coco.getImgIds()\n",
    "iou_thr = 0.55\n",
    "skip_box_thr = 0.0\n",
    "sigma = 0.1\n",
    "\n",
    "class_num = 11\n",
    "for i in range(len(output0)):\n",
    "    out0 = output0[i]\n",
    "    out1 = output1[i]\n",
    "    out2 = output2[i]\n",
    "#     out3 = output3[i][0]\n",
    "#     out4 = output4[i]\n",
    "#     out5 = output5[i]\n",
    "    weights = [0.8,\n",
    "               0.8,\n",
    "               0.8,\n",
    "#                0.15, \n",
    "#                0.5\n",
    "#                0.5\n",
    "              ]\n",
    "    \n",
    "    boxes_list0 = []\n",
    "    boxes_list1 = []\n",
    "    boxes_list2 = []\n",
    "#     boxes_list3 = []\n",
    "#     boxes_list4 = []\n",
    "#     boxes_list5 = []\n",
    "\n",
    "    scores_list0 = []\n",
    "    scores_list1 = []\n",
    "    scores_list2 = []\n",
    "#     scores_list3 = []\n",
    "#     scores_list4 = []\n",
    "#     scores_list5 = []\n",
    "\n",
    "    labels_list0 = []\n",
    "    labels_list1 = []\n",
    "    labels_list2 = []\n",
    "#     labels_list3 = []\n",
    "#     labels_list4 = []\n",
    "    for j in range(class_num):\n",
    "        boxes_list0 += (out0[j][:, :4]/512).tolist()\n",
    "        boxes_list1 += (out1[j][:, :4]/512).tolist()\n",
    "        boxes_list2 += (out2[j][:, :4]/512).tolist()\n",
    "#         boxes_list3 += (out3[j][:, :4]/512).tolist()\n",
    "#         boxes_list4 += (out4[j][:, :4]/512).tolist()\n",
    "\n",
    "        scores_list0 += out0[j][:, 4].tolist()\n",
    "        scores_list1 += out1[j][:, 4].tolist()\n",
    "        scores_list2 += out2[j][:, 4].tolist()\n",
    "#         scores_list3 += out3[j][:, 4].tolist()\n",
    "#         scores_list4 += out4[j][:, 4].tolist()\n",
    "        \n",
    "        # 0 class는 분류 못해서 +1\n",
    "        labels_list0 += [j] * len(out0[j][:, 4].tolist())\n",
    "        labels_list1 += [j] * len(out1[j][:, 4].tolist())\n",
    "        labels_list2 += [j] * len(out2[j][:, 4].tolist())\n",
    "#         labels_list3 += [j] * len(out3[j][:, 4].tolist())\n",
    "#         labels_list4 += [j] * len(out4[j][:, 4].tolist())\n",
    "\n",
    "    \n",
    "    boxes_list = [boxes_list0, \n",
    "                  boxes_list1, \n",
    "                  boxes_list2, \n",
    "#                   boxes_list3, \n",
    "#                   boxes_list4\n",
    "                 ]\n",
    "    scores_list = [scores_list0, \n",
    "                   scores_list1, \n",
    "                   scores_list2, \n",
    "#                    scores_list3, \n",
    "#                    scores_list4\n",
    "                  ]\n",
    "    labels_list = [labels_list0, \n",
    "                   labels_list1, \n",
    "                   labels_list2, \n",
    "#                    labels_list3, \n",
    "#                    labels_list4\n",
    "                  ]\n",
    "\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, weights=weights, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    \n",
    "    prediction_string = ''\n",
    "    image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "    \n",
    "    predict_zip = list(zip(boxes, scores, labels))\n",
    "    predict_zip.sort(key = lambda x : (x[2], -x[1]))\n",
    "    for box, score, label in predict_zip:\n",
    "        if score>=0.1:\n",
    "            prediction_string += str(int(label)) + ' ' + f'{score:.8f}' + ' ' + f'{box[0]*512:.5f}' + ' ' + f'{box[1]*512:.5f}' + ' ' + f'{box[2]*512:.5f}' + ' ' + f'{box[3]*512:.5f}' + ' '\n",
    "        else:\n",
    "            prediction_string += str(int(label)) + ' ' + f'{score:.9f}' + ' ' + f'{box[0]*512:.5f}' + ' ' + f'{box[1]*512:.5f}' + ' ' + f'{box[2]*512:.5f}' + ' ' + f'{box[3]*512:.5f}' + ' '\n",
    "\n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(image_info['file_name'])\n",
    "\n",
    "epoch = 12\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.work_dir, f'submission_{epoch}_ensemble3(08 08 08)iou0565_final.csv'), index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}